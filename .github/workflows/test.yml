name: Test

on:
  workflow_run:
    workflows: ["Build"]
    types:
      - completed
    branches: [ main, develop ]
  workflow_dispatch:
  pull_request:
    branches: [ main, develop ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Only run tests if build workflow succeeded
  check-build:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    outputs:
      build-success: ${{ steps.check.outputs.success }}
    steps:
    - name: Check build workflow status
      id: check
      run: |
        # Allow tests to run if:
        # 1. Triggered by successful build workflow
        # 2. Manual dispatch
        # 3. Pull request (tests run directly for PRs)
        if [[ "${{ github.event.workflow_run.conclusion }}" == "success" ]] || \
           [[ "${{ github.event_name }}" == "workflow_dispatch" ]] || \
           [[ "${{ github.event_name }}" == "pull_request" ]]; then
          echo "success=true" >> $GITHUB_OUTPUT
          echo "Tests approved to run"
        else
          echo "success=false" >> $GITHUB_OUTPUT
          echo "Build workflow failed or was cancelled. Skipping tests."
          exit 1
        fi

  unit-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Clear pytest cache
      run: |
        # Clear any existing pytest cache
        rm -rf .pytest_cache
    
    - name: Run unit tests
      env:
        TESTING: true
        OPENAI_API_KEY: test-key
        USE_MOCK_API: true
        REDIS_URL: redis://localhost:6379
      run: |
        python run_tests.py --unit --coverage --output-dir test-results
    
    - name: Upload unit test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results-py${{ matrix.python-version }}
        path: test-results/
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: test-results/coverage.xml
        flags: unit
        name: unit-tests

  integration-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Clear pytest cache and verify configuration  
      run: |
        rm -rf .pytest_cache
        echo "=== Integration test collection ==="
        python -m pytest -m integration --collect-only --quiet | grep "collected" || echo "No integration tests collected!"
    
    - name: Run integration tests
      env:
        TESTING: true
        OPENAI_API_KEY: test-key
        USE_MOCK_API: true
        REDIS_URL: redis://localhost:6379
      run: |
        python run_tests.py --integration --coverage --output-dir test-results
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: test-results/
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: test-results/coverage.xml
        flags: integration
        name: integration-tests

  api-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-web.txt
        pip install -r requirements-test.txt
    
    - name: Clear pytest cache and verify configuration
      run: |
        rm -rf .pytest_cache
        echo "=== API test collection ==="
        python -m pytest -m api --collect-only --quiet | grep "collected" || echo "No API tests collected!"
    
    - name: Run API tests
      env:
        TESTING: true
        OPENAI_API_KEY: test-key
        USE_MOCK_API: true
        REDIS_URL: redis://localhost:6379
        WEB_HOST: 127.0.0.1
        WEB_PORT: 8000
      run: |
        python run_tests.py --api --coverage --output-dir test-results
    
    - name: Upload API test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: api-test-results
        path: test-results/
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: test-results/coverage.xml
        flags: api
        name: api-tests

  cli-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Clear pytest cache and verify configuration
      run: |
        rm -rf .pytest_cache
        echo "=== CLI test collection ==="
        python -m pytest -m cli --collect-only --quiet | grep "collected" || echo "No CLI tests collected!"
    
    - name: Run CLI tests
      env:
        TESTING: true
        OPENAI_API_KEY: test-key
        USE_MOCK_API: true
      run: |
        python run_tests.py --cli --coverage --output-dir test-results
    
    - name: Upload CLI test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: cli-test-results
        path: test-results/
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: test-results/coverage.xml
        flags: cli
        name: cli-tests

  docker-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Free up disk space
      run: |
        # Remove unnecessary packages and files to free up disk space
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL
        sudo docker system prune -af
        df -h
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Prepare test directories
      run: |
        # Configure directories with defaults
        export HOST_TEST_RESULTS_DIR="${HOST_TEST_RESULTS_DIR:-./test-results}"
        export HOST_COVERAGE_DIR="${HOST_COVERAGE_DIR:-./coverage-reports}"
        export HOST_TEMP_DIR="${HOST_TEMP_DIR:-./temp}"
        
        # Clean and create test result directories
        rm -rf "$HOST_TEST_RESULTS_DIR" docker-test-results "$HOST_COVERAGE_DIR" "$HOST_TEMP_DIR"
        mkdir -p "$HOST_TEST_RESULTS_DIR" docker-test-results "$HOST_COVERAGE_DIR" "$HOST_TEMP_DIR"
        
        # Export for subsequent steps
        echo "HOST_TEST_RESULTS_DIR=$HOST_TEST_RESULTS_DIR" >> $GITHUB_ENV
        echo "HOST_COVERAGE_DIR=$HOST_COVERAGE_DIR" >> $GITHUB_ENV
        echo "HOST_TEMP_DIR=$HOST_TEMP_DIR" >> $GITHUB_ENV
    
    - name: Build test image
      uses: docker/build-push-action@v5
      with:
        context: .
        target: testing
        load: true
        tags: raft-toolkit:test
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Run tests in Docker (sequential)
      run: |
        # Run tests sequentially to avoid disk space issues
        echo "Running unit tests..."
        docker run --rm \
          -e TESTING=true \
          -e OPENAI_API_KEY=test-key \
          -e USE_MOCK_API=true \
          -v "$PWD/test-results:/tmp/test-results" \
          raft-toolkit:test \
          python run_tests.py --unit --coverage --output-dir /tmp/test-results/unit
        
        echo "Running integration tests..."
        docker run --rm \
          -e TESTING=true \
          -e OPENAI_API_KEY=test-key \
          -e USE_MOCK_API=true \
          -v "$PWD/test-results:/tmp/test-results" \
          raft-toolkit:test \
          python run_tests.py --integration --coverage --output-dir /tmp/test-results/integration
        
        echo "Running API tests..."
        docker run --rm \
          -e TESTING=true \
          -e OPENAI_API_KEY=test-key \
          -e USE_MOCK_API=true \
          -v "$PWD/test-results:/tmp/test-results" \
          raft-toolkit:test \
          python run_tests.py --api --coverage --output-dir /tmp/test-results/api
        
        echo "Running CLI tests..."
        docker run --rm \
          -e TESTING=true \
          -e OPENAI_API_KEY=test-key \
          -e USE_MOCK_API=true \
          -v "$PWD/test-results:/tmp/test-results" \
          raft-toolkit:test \
          python run_tests.py --cli --coverage --output-dir /tmp/test-results/cli
    
    - name: Prepare test results directory
      if: always()
      run: |
        # Consolidate test results from all test suites
        mkdir -p docker-test-results
        if [ -d "test-results" ]; then
          cp -r test-results/* docker-test-results/ 2>/dev/null || true
        fi
        
        # List what we collected
        echo "Docker test results structure:"
        find docker-test-results -type f -name "*.xml" -o -name "*.html" | head -20
    
    - name: Upload Docker test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: docker-test-results
        path: docker-test-results/

  kubernetes-tests:
    needs: check-build
    if: needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-k8s.txt
        pip install yamllint
    
    - name: Install kubectl and kustomize
      run: |
        # Install kubectl
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        
        # Install kustomize
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
        sudo mv kustomize /usr/local/bin/
    
    - name: Validate Kubernetes manifests
      run: |
        echo "## Kubernetes Manifest Validation" >> $GITHUB_STEP_SUMMARY
        
        # Validate YAML syntax
        for file in $(find k8s -name "*.yaml" -o -name "*.yml"); do
          if ! yamllint -d relaxed "$file" >/dev/null 2>&1; then
            echo "❌ YAML syntax error in $file" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
        done
        echo "✅ All YAML files have valid syntax" >> $GITHUB_STEP_SUMMARY
        
        # Validate Kubernetes resources
        for cloud in aks eks gks; do
          cd k8s/overlays/$cloud
          if kustomize build . | kubectl apply --dry-run=client -f - >/dev/null 2>&1; then
            echo "✅ $cloud overlay is valid" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ $cloud overlay validation failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          cd ../../..
        done
    
    - name: Test deployment scripts
      run: |
        echo "### Deployment Script Tests" >> $GITHUB_STEP_SUMMARY
        
        # Test script help functionality
        for script in k8s/scripts/*.sh; do
          if [ -f "$script" ]; then
            script_name=$(basename "$script")
            if bash "$script" --help >/dev/null 2>&1; then
              echo "✅ $script_name help works" >> $GITHUB_STEP_SUMMARY
            else
              echo "⚠️ $script_name help failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
        done

  test-summary:
    needs: [unit-tests, integration-tests, api-tests, cli-tests, docker-tests, kubernetes-tests]
    if: always() && needs.check-build.outputs.build-success == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - name: Generate test summary
      id: summary
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| API Tests | ${{ needs.api-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| CLI Tests | ${{ needs.cli-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Docker Tests | ${{ needs.docker-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Kubernetes Tests | ${{ needs.kubernetes-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        
        # Set overall status
        if [[ "${{ needs.unit-tests.result }}" == "success" && 
              "${{ needs.integration-tests.result }}" == "success" && 
              "${{ needs.api-tests.result }}" == "success" && 
              "${{ needs.cli-tests.result }}" == "success" && 
              "${{ needs.docker-tests.result }}" == "success" && 
              "${{ needs.kubernetes-tests.result }}" == "success" ]]; then
          echo "tests-passed=true" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🎉 **All tests passed!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "tests-passed=false" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "💥 **Some tests failed. Please check the individual test results.**" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi
    
    outputs:
      tests-passed: ${{ steps.summary.outputs.tests-passed }}