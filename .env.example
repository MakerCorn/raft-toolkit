# RAFT Toolkit Configuration
# Copy this file to .env and configure your settings

# ================================
# OpenAI Configuration
# ================================
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_API_BASE_URL=http://localhost:11434/v1  # For Ollama

# ================================
# Azure OpenAI Configuration (optional)
# ================================
# Set to 'true' to enable Azure OpenAI
AZURE_OPENAI_ENABLED=false
# AZURE_OPENAI_ENDPOINT=https://your-azure-endpoint.openai.azure.com/
# AZURE_OPENAI_KEY=your_azure_api_key
# AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name

# ================================
# RAFT Application Configuration
# ================================

# I/O Configuration
RAFT_OUTPUT=./raft_output
RAFT_OUTPUT_FORMAT=hf
RAFT_OUTPUT_TYPE=jsonl
# RAFT_OUTPUT_CHAT_SYSTEM_PROMPT=You are a helpful assistant.

# Processing Configuration
RAFT_DISTRACTORS=1
RAFT_P=1.0
RAFT_QUESTIONS=5
RAFT_CHUNK_SIZE=512
RAFT_DOCTYPE=pdf
RAFT_CHUNKING_STRATEGY=semantic
# RAFT_CHUNKING_PARAMS={"overlap": 50, "min_chunk_size": 200}

# AI Model Configuration
RAFT_EMBEDDING_MODEL=nomic-embed-text
RAFT_COMPLETION_MODEL=llama3.2
RAFT_SYSTEM_PROMPT_KEY=gpt

# Azure Configuration
RAFT_USE_AZURE_IDENTITY=false

# Performance Configuration
RAFT_WORKERS=1
RAFT_EMBED_WORKERS=1
RAFT_PACE=true
RAFT_AUTO_CLEAN_CHECKPOINTS=false

# Template Configuration
RAFT_TEMPLATES=./templates/

# ================================
# Web Server Configuration
# ================================
WEB_HOST=127.0.0.1
WEB_PORT=8000
WEB_RELOAD=false

# ================================
# Logging Configuration
# ================================
LOG_LEVEL=INFO
LOG_FORMAT=json  # or 'text'