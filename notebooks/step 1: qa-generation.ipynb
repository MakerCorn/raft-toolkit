{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT\n",
    "\n",
    "Retrival Augmented Fine-Tuning\n",
    "\n",
    "## Chunking and Question Generation\n",
    "\n",
    "### 1. Setup the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_name = \"output_sample_data\"\n",
    "doc_path = \"../../sample_data/\"\n",
    "ds_path = f\"../../{ds_name}\"\n",
    "print(\"Creating dataset: \" + ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean up the DEMO folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up demo folder only if it's a DEMO dataset\n",
    "if ds_path.endswith(\"demo\"):\n",
    "    import shutil\n",
    "    print(f\"Cleaning demo folder {ds_path}\")\n",
    "    shutil.rmtree(ds_path, ignore_errors=True)\n",
    "    print(f\"Cleaning demo checkpoints folder {ds_path}\")\n",
    "    shutil.rmtree(ds_path + \"-checkpoints\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Q/A/CoT fine-tuning dataset using RAFT from the domain specific documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ../raft.py \\\n",
    "    --datapath \"$doc_path\" \\\n",
    "    --output $ds_path \\\n",
    "    --distractors 1 \\\n",
    "    --doctype pdf \\\n",
    "    --chunk_size 2000 \\\n",
    "    --questions 3 \\\n",
    "    --workers 1 \\\n",
    "    --system-prompt-key gpt \\\n",
    "    --completion_model gpt-4 \\\n",
    "    --embedding_model text-embedding-ada-002 \\\n",
    "    --templates \"../templates/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation and evaluation splits\n",
    "\n",
    "### 3. Setup file locations for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_arrow_file = f\"{ds_path}/data-00000-of-00001.arrow\"\n",
    "dataset_path = f\"{ds_path}-files/{ds_name}-full.jsonl\"\n",
    "dataset_path_hf = f\"{ds_path}-files/{ds_name}-hf.full.jsonl\"\n",
    "\n",
    "dataset_path_hf_train = f\"{ds_path}-files/{ds_name}-hf.train.jsonl\"\n",
    "dataset_path_hf_valid = f\"{ds_path}-files/{ds_name}-hf.valid.jsonl\"\n",
    "dataset_path_hf_eval = f\"{ds_path}-files/{ds_name}-hf.eval.jsonl\"\n",
    "\n",
    "dataset_path_ft_train = f\"{ds_path}-files/{ds_name}-ft.train.jsonl\"\n",
    "dataset_path_ft_train_filtered = f\"{ds_path}-files/{ds_name}-ft.train.filtered.jsonl\"\n",
    "dataset_path_ft_valid = f\"{ds_path}-files/{ds_name}-ft.valid.jsonl\"\n",
    "dataset_path_ft_valid_filtered = f\"{ds_path}-files/{ds_name}-ft.valid.filtered.jsonl\"\n",
    "dataset_path_ft_eval = f\"{ds_path}-files/{ds_name}-ft.eval.jsonl\"\n",
    "\n",
    "print(f\"Reading arrow file {raft_arrow_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Export the full Hugging Face dataset to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../format.py \\\n",
    "    --input $raft_arrow_file \\\n",
    "    --output $dataset_path_hf \\\n",
    "    --output-format hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_full_df = pd.read_json(dataset_path_hf, lines=True)\n",
    "hf_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Do the splitting\n",
    "    - 80% Training Data / 10% Evaluation Data / 10% Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into 80%/10%/10%\n",
    "import numpy as np\n",
    "\n",
    "samples_count = len(hf_full_df)\n",
    "\n",
    "hf_train_df, hf_valid_df, hf_eval_df = np.split(hf_full_df, [int(.8*samples_count), int(.9*samples_count)])\n",
    "\n",
    "hf_train_df.to_json(dataset_path_hf_train, orient=\"records\", lines=True)\n",
    "hf_valid_df.to_json(dataset_path_hf_valid, orient=\"records\", lines=True)\n",
    "hf_eval_df.to_json(dataset_path_hf_eval, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export training and validation datasets into JSONL format\n",
    "\n",
    "### 6. Export training dataset for a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../format.py \\\n",
    "    --input $dataset_path_hf_train \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_train \\\n",
    "    --output-format chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_train_df = pd.read_json(dataset_path_ft_train, lines=True)\n",
    "dataset_path_ft_train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Export the validation dataset for a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../format.py \\\n",
    "    --input $dataset_path_hf_valid \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_valid \\\n",
    "    --output-format chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_valid_df = pd.read_json(dataset_path_ft_valid, lines=True)\n",
    "dataset_path_ft_valid_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Export evaluation dataset into JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../format.py \\\n",
    "    --input $dataset_path_hf_eval \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_eval \\\n",
    "    --output-format eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_eval_df = pd.read_json(dataset_path_ft_eval, lines=True)\n",
    "dataset_path_ft_eval_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Steps\n",
    "\n",
    "### Filter the data based on the token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Function to count tokens\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def transform_entry(entry):\n",
    "    prompt_parts = []\n",
    "    completion = None\n",
    "\n",
    "    for message in entry['messages']:\n",
    "        if message['role'] == 'system':\n",
    "            prompt_parts.append(message['content'])\n",
    "        elif message['role'] == 'user':\n",
    "            if prompt_parts:\n",
    "                prompt_parts.append(\"User: \" + message['content'])\n",
    "            else:\n",
    "                prompt_parts = [\"User: \" + message['content']]\n",
    "        elif message['role'] == 'assistant':\n",
    "            completion = \"Assistant: \" + message['content']\n",
    "    \n",
    "    prompt = \"\\n\".join(prompt_parts)\n",
    "    return prompt, completion\n",
    "\n",
    "def filter_data(entries, max_tokens=8192):\n",
    "    filtered_entries = []\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "    for entry in entries:\n",
    "        prompt, completion = transform_entry(entry)\n",
    "                \n",
    "        total_text = f\"{prompt} {completion}\"  # Combine prompt and completion\n",
    "        if count_tokens(total_text) <= max_tokens:\n",
    "            filtered_entries.append(entry)\n",
    "    return filtered_entries\n",
    "\n",
    "def load_chat_completions(file_path):\n",
    "    try:\n",
    "        entries = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    entries.append(entry)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Skipping a line that could not be decoded.\")\n",
    "        return entries\n",
    "    except FileNotFoundError:\n",
    "        print(\"The specified file was not found.\")\n",
    "        return []\n",
    "\n",
    "# Function to write filtered entries to a JSONL file\n",
    "def write_to_jsonl(filtered_entries, output_file_path):\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for entry in filtered_entries:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')  # Ensure each JSON object is on a new line\n",
    "\n",
    "unfiltered_entries = load_chat_completions(dataset_path_ft_train)\n",
    "filtered_entries = filter_data(unfiltered_entries)\n",
    "write_to_jsonl(filtered_entries, dataset_path_ft_train_filtered)\n",
    "\n",
    "unfiltered_entries = load_chat_completions(dataset_path_ft_valid)\n",
    "filtered_entries = filter_data(unfiltered_entries)\n",
    "write_to_jsonl(filtered_entries, dataset_path_ft_valid_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_train_filtered_df = pd.read_json(dataset_path_ft_train_filtered, lines=True)\n",
    "dataset_path_ft_train_filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI Tool to validate the completions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! openai tools fine_tunes.prepare_data -f ../../output_data_1000.completion.jsonl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
